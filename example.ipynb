{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1cec702",
   "metadata": {},
   "source": [
    "# MAF User manual"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5441a06f",
   "metadata": {},
   "source": [
    "MAF was based on AIF360. So if you will use MAF on python code, it is helpful that read the AIF360 API document https://aif360.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b001aa22",
   "metadata": {},
   "source": [
    "MAF consists of DataSet, Metric and Algorithm modules (It is same with AIF360). For using MAF, first of all, you need to load the dataset using DataSet module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b87ed0",
   "metadata": {},
   "source": [
    "## 1. DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ede82a",
   "metadata": {},
   "source": [
    "### 1.1. Read from file (csv, tsv, npy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e0f6104",
   "metadata": {},
   "source": [
    "You can think reading the data from file first of all. MAF can do it. The type of files must be a table form like csv, tsv, npy. But, it is different which read a npy or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae9a08",
   "metadata": {},
   "source": [
    "#### 1.1.1. Read npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9237436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sample npy file\n",
    "import numpy as np\n",
    "\n",
    "feature = np.random.random((500, 2))\n",
    "target = np.random.randint(0, 2, size=500)\n",
    "bias = np.random.randint(0, 2, size=500)\n",
    "\n",
    "whole = np.column_stack((feature, bias, target))\n",
    "np.save('sample.npy', whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed05d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 17:57:38.188374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/e/MAF_API/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-28 17:57:38.188410: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Use RawDataSet\n",
    "from DataSet import RawDataSet\n",
    "\n",
    "## Required parameters\n",
    "#    - target column index (int) : target_col_idx\n",
    "#    - bias column index (int) : bias_col_idx\n",
    "## Optional parameters\n",
    "#    - prediction column index (int) : pred_col_idx\n",
    "\n",
    "dataset = RawDataSet('sample.npy', target_col_idx=3, bias_col_idx=2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2691493d",
   "metadata": {},
   "source": [
    "The RawDataSet object has attributes which the names are feature, feature_only, bias, and target. The types of attributes are np.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a327c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature:  (500, 3)\n",
      "Shape of feature_only:  (500, 2)\n",
      "Shape of target:  (500,)\n",
      "Shape of bias:  (500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of feature: \", dataset.feature.shape)\n",
    "print('Shape of feature_only: ', dataset.feature_only.shape)\n",
    "print('Shape of target: ', dataset.target.shape)\n",
    "print('Shape of bias: ', dataset.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fc3ba",
   "metadata": {},
   "source": [
    "#### 1.1.2. Read table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4b2251a",
   "metadata": {},
   "source": [
    "In many cases, you will deal with data using pandas. MAF also can read the table form csv, tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a49298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heavy_Makeup</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>12278</th>\n",
       "      <th>12279</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>251</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Heavy_Makeup  Male    0    1    2    3    4    5    6    7  ...  12278  \\\n",
       "0            -1    -1  255  255  253  254  254  251  253  254  ...      0   \n",
       "1            -1    -1   32   61   70   14   32   43   16   22  ...      4   \n",
       "2             1    -1   27   23   25   13   11   12    4    3  ...     16   \n",
       "3             1    -1   30   31   25   38   39   33   52   53  ...     13   \n",
       "4            -1    -1   54   39   10   54   39   10   54   39  ...     21   \n",
       "\n",
       "   12279  12280  12281  12282  12283  12284  12285  12286  12287  \n",
       "0      0      0      0      0      0      0      0      0      0  \n",
       "1      2      2      2      1      1      1      2      2      2  \n",
       "2     56     24     15     46     24     16     38     21     10  \n",
       "3     49     30     17     67     45     31     85     58     40  \n",
       "4     12     17     18     10     16     16     14     16     18  \n",
       "\n",
       "[5 rows x 12290 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sample data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('./CelebA_samples.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e89857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample data using RawDataSet\n",
    "dataset = RawDataSet('./CelebA_samples.csv', header=0, seperator=',', \n",
    "                     target_col_name='Male', bias_col_name='Heavy_Makeup', cate_cols=['Male', 'Heavy_Makeup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c80b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature:  (500, 12289)\n",
      "Shape of feature_only:  (500, 12288)\n",
      "Shape of target:  (500,)\n",
      "Shape of bias:  (500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of feature: \", dataset.feature.shape)\n",
    "print('Shape of feature_only: ', dataset.feature_only.shape)\n",
    "print('Shape of target: ', dataset.target.shape)\n",
    "print('Shape of bias: ', dataset.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e7586",
   "metadata": {},
   "source": [
    "### 1.2. aifData"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2193222",
   "metadata": {},
   "source": [
    "The RawDataSet is a dataset object for using state of the art algorithms. For metrics or ordinary algorithms, you must using aifData. To do this, pandas.DataFrame object is used as a input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f26be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSet import aifData\n",
    "\n",
    "df = pd.read_table('./CelebA_samples.csv', sep=',')\n",
    "\n",
    "aif_data = aifData(df=df, label_name='Male', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Heavy_Makeup'], privileged_classes=[[1]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75c258ec",
   "metadata": {},
   "source": [
    "Necessary parameters are df, label_name, favorable_classes, protected_attribute_names, and privileged_classes. Optional parameters are same with aif360.datasets.StandardDataset (https://aif360.readthedocs.io/en/stable/modules/generated/aif360.datasets.StandardDataset.html#aif360.datasets.StandardDataset)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ff3e0c6",
   "metadata": {},
   "source": [
    "With the aifData, you can use the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b8d58",
   "metadata": {},
   "source": [
    "## 2. Metrics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d82e9725",
   "metadata": {},
   "source": [
    "Bias could be contained on data and prediction. There are two metrics for measuring bias DataMetric, ClassificationMetric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fccca",
   "metadata": {},
   "source": [
    "### 2.1. Metrics for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387ddb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Metric import DataMetric\n",
    "\n",
    "metric = DataMetric(aif_data, privilege=[{'Heavy_Makeup': 1}], unprivilege=[{'Heavy_Makeup': -1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b14b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatives N 304\n",
      "Positives N 196\n",
      "Base rate 0.392\n",
      "Statistical parity difference 0.6468646864686468\n",
      "Consistency 0.3735999999999997\n"
     ]
    }
   ],
   "source": [
    "print('Negatives N', metric.num_negative())\n",
    "print('Positives N', metric.num_positive())\n",
    "print('Base rate', metric.base_rate())\n",
    "print('Statistical parity difference', metric.statistical_parity_difference())\n",
    "print('Consistency', metric.consistency())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0b96f",
   "metadata": {},
   "source": [
    "### 2.2. Metrics for prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc9ec299",
   "metadata": {},
   "source": [
    "After mitigating bias, it need to measure how much bias is mitigated. So, you want to measure bias on predictions. Measuring bias on predictions is based on confusion matrix. The metrics use TP, TN, FP, FN. First of all, you need a model for prediction. In this example, we will use a SGD classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1153fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, train_size=0.7, shuffle=True, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92f0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aif = aifData(df=train_df, label_name='Male', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Heavy_Makeup'], privileged_classes=[[1]])\n",
    "test_aif = aifData(df=test_df, label_name='Male', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Heavy_Makeup'], privileged_classes=[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631bb9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(max_iter=5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "model.fit(train_aif.features, train_aif.labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d9d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_aif.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5e2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Metric import ClassificationMetric\n",
    "\n",
    "clsMetric = ClassificationMetric(test_aif, privilege=[{'Heavy_Makeup': 1}], unprivilege=[{'Heavy_Makeup': -1}],\n",
    "                                prediction_vector=prediction, target_label_name='Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b7c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.9672131147540983, 'TNR': 0.39325842696629215, 'FPR': 0.6067415730337079, 'FNR': 0.03278688524590164, 'PPV': 0.5221238938053098, 'NPV': 0.9459459459459459, 'FDR': 0.4778761061946903, 'FOR': 0.05405405405405406, 'ACC': 0.6266666666666667}\n",
      "Error rate:  0.3733333333333333\n",
      "Average odds difference:  0.5706755228942906\n",
      "Average absolute odds difference:  0.5706755228942906\n",
      "Selection rate:  0.7533333333333333\n",
      "Disparate impact:  1.616161616161616\n",
      "Statistical parity difference:  0.3388888888888888\n",
      "Generalized entropy index:  0.0697970787177727\n",
      "Theil index:  0.07296113877660586\n",
      "Equal opportunity difference:  0.9672131147540983\n"
     ]
    }
   ],
   "source": [
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa32a7b",
   "metadata": {},
   "source": [
    "## 3. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3916d67",
   "metadata": {},
   "source": [
    "### 3.1. AIF360 algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2930187f",
   "metadata": {},
   "source": [
    "Bias mitigation algorithms are basically same with aif360. Usage is also same with it. We will show you a reweighing only here, but all other usage of algorithms could be used by same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a8da170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.Preprocessing import RW\n",
    "\n",
    "rw = RW(unprivileged_groups=[{'Heavy_Makeup': -1}], privileged_groups = [{'Heavy_Makeup': 1}])\n",
    "tfm_train_aif = rw.fit_transform(train_aif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46bfbc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(max_iter=5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the bias\n",
    "model.fit(tfm_train_aif.features, tfm_train_aif.labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e03f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.819672131147541, 'TNR': 0.651685393258427, 'FPR': 0.34831460674157305, 'FNR': 0.18032786885245902, 'PPV': 0.6172839506172839, 'NPV': 0.8405797101449275, 'FDR': 0.38271604938271603, 'FOR': 0.15942028985507245, 'ACC': 0.72}\n",
      "Error rate:  0.28\n",
      "Average odds difference:  0.48397399660825324\n",
      "Average absolute odds difference:  0.48397399660825324\n",
      "Selection rate:  0.54\n",
      "Disparate impact:  2.3333333333333335\n",
      "Statistical parity difference:  0.39999999999999997\n",
      "Generalized entropy index:  0.10207612456747402\n",
      "Theil index:  0.12763171113256225\n",
      "Equal opportunity difference:  0.819672131147541\n"
     ]
    }
   ],
   "source": [
    "tfm_predict = model.predict(test_aif.features)\n",
    "clsMetric = ClassificationMetric(test_aif, privilege=[{'Heavy_Makeup': 1}], unprivilege=[{'Heavy_Makeup': -1}],\n",
    "                                prediction_vector=tfm_predict, target_label_name='Male')\n",
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73f9937b",
   "metadata": {},
   "source": [
    "It is helpful see the AIF350 API documents (https://aif360.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b750c1",
   "metadata": {},
   "source": [
    "### 3.2. S.O.T.A. Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50053c6d",
   "metadata": {},
   "source": [
    "If you want to test this algorithm on image data (like CelebA), it is recommended to prepare GPU environment. \n",
    "In CPU environment, these S.O.T.A. algorithms are too slow to check the result in time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17d11d",
   "metadata": {},
   "source": [
    "#### 3.2.1. FairBatch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afd54f46",
   "metadata": {},
   "source": [
    "Reference (https://github.com/yuji-roh/fairbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "112522ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare raw dataset\n",
    "#dataset = RawDataSet('CelebA_samples.csv', target_col_name='Male', bias_col_name='Heavy_Makeup')\n",
    "dataset = RawDataSet('sample.npy', target_col_idx=3, bias_col_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3143b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on [[[  cpu  ]]] device.\n",
      "Epoch [0] || Average loss : 0.5789919444918632\n",
      "Epoch [10] || Average loss : 0.47548798948526383\n",
      "Epoch [20] || Average loss : 0.4754349333047867\n",
      "Epoch [30] || Average loss : 0.4737826558947563\n",
      "Epoch [40] || Average loss : 0.4731024914979935\n",
      "Epoch [50] || Average loss : 0.47203448742628096\n",
      "Epoch [60] || Average loss : 0.4712680643796921\n",
      "Epoch [70] || Average loss : 0.47039511740207673\n",
      "Epoch [80] || Average loss : 0.46937511473894117\n",
      "Epoch [90] || Average loss : 0.4684423300623894\n",
      "Epoch [100] || Average loss : 0.4675027135014534\n",
      "Epoch [110] || Average loss : 0.4665996280312538\n",
      "Epoch [120] || Average loss : 0.4654026520252228\n",
      "Epoch [130] || Average loss : 0.4658711650967598\n",
      "Epoch [140] || Average loss : 0.4643395459651947\n",
      "Epoch [150] || Average loss : 0.46237372130155563\n",
      "Epoch [160] || Average loss : 0.46037332236766815\n",
      "Epoch [170] || Average loss : 0.4605739066004753\n",
      "Epoch [180] || Average loss : 0.4542435497045517\n",
      "Epoch [190] || Average loss : 0.4509874847531319\n",
      "Epoch [200] || Average loss : 0.44452848345041274\n",
      "Epoch [210] || Average loss : 0.43911045402288434\n",
      "Epoch [220] || Average loss : 0.4337793293595314\n",
      "Epoch [230] || Average loss : 0.4289470857381821\n",
      "Epoch [240] || Average loss : 0.42474750339984896\n",
      "Epoch [250] || Average loss : 0.4217945425212383\n",
      "Epoch [260] || Average loss : 0.41789853513240816\n",
      "Epoch [270] || Average loss : 0.41616081312298775\n",
      "Epoch [280] || Average loss : 0.419371075630188\n",
      "Epoch [290] || Average loss : 0.4098379358649254\n",
      "\n",
      "########## Train finished ##########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.sota import FairBatch\n",
    "# Get prediction\n",
    "fb_pred = FairBatch.train(kaif_raw_dataset=dataset, batch_size=4, alpha=2, target_fairness=\"eqopp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "599d6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load('sample.npy')\n",
    "df = pd.DataFrame(arr, columns=['Attr1', 'Attr2', 'Bias', 'Target'])\n",
    "aif_data = aifData(df=df, label_name='Target', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Bias'], privileged_classes=[[1]])\n",
    "clsMetric = ClassificationMetric(aif_data, privilege=[{'Bias': 1}], unprivilege=[{'Bias': 0}],\n",
    "                                prediction_vector=fb_pred, target_label_name='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86410d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.43824701195219123, 'TNR': 0.6987951807228916, 'FPR': 0.30120481927710846, 'FNR': 0.5617529880478087, 'PPV': 0.5945945945945946, 'NPV': 0.5523809523809524, 'FDR': 0.40540540540540543, 'FOR': 0.44761904761904764, 'ACC': 0.568}\n",
      "Error rate:  0.43200000000000005\n",
      "Average odds difference:  -0.7039382373351839\n",
      "Average absolute odds difference:  0.7039382373351839\n",
      "Selection rate:  0.37\n",
      "Disparate impact:  0.0\n",
      "Statistical parity difference:  -0.7034220532319392\n",
      "Generalized entropy index:  0.27512794920257405\n",
      "Theil index:  0.381130562211169\n",
      "Equal opportunity difference:  -0.8396946564885496\n"
     ]
    }
   ],
   "source": [
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1304f",
   "metadata": {},
   "source": [
    "#### 3.2.2. Fair Feature Distillation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25fc407d",
   "metadata": {},
   "source": [
    "Reference (https://github.com/DQle38/Fair-Feature-Distillation-for-Visual-Recognition)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebafa74d",
   "metadata": {},
   "source": [
    "Fair Feature Distillation can be used only on image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd6c24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RawDataSet('./CelebA_samples.csv', header=0, seperator=',', \n",
    "                 target_col_name='Male', bias_col_name='Heavy_Makeup', cate_cols=['Male', 'Heavy_Makeup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aedb73ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on [[[  cpu  ]]] device.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.sota.FairFeatureDistillation import FFD\n",
    "\n",
    "ffd = FFD(rds, n_epoch=20, batch_size=20, learning_rate=0.01, image_shape=[3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb13541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train teacher start\n",
      "Epoch [1/20], Batch [0/20], Loss 0.0\n",
      "Epoch [1/20], Batch [10/20], Loss 0.0\n",
      "Epoch [2/20], Batch [0/20], Loss 0.0\n",
      "Epoch [2/20], Batch [10/20], Loss 0.0\n",
      "Epoch [3/20], Batch [0/20], Loss 0.0\n",
      "Epoch [3/20], Batch [10/20], Loss 0.0\n",
      "Epoch [4/20], Batch [0/20], Loss 0.0\n",
      "Epoch [4/20], Batch [10/20], Loss 0.0\n",
      "Epoch [5/20], Batch [0/20], Loss 0.0\n",
      "Epoch [5/20], Batch [10/20], Loss 0.0\n",
      "Epoch [6/20], Batch [0/20], Loss 0.0\n",
      "Epoch [6/20], Batch [10/20], Loss 0.0\n",
      "Epoch [7/20], Batch [0/20], Loss 0.0\n",
      "Epoch [7/20], Batch [10/20], Loss 0.0\n",
      "Epoch [8/20], Batch [0/20], Loss 0.0\n",
      "Epoch [8/20], Batch [10/20], Loss 0.0\n",
      "Epoch [9/20], Batch [0/20], Loss 0.0\n",
      "Epoch [9/20], Batch [10/20], Loss 0.0\n",
      "Epoch [10/20], Batch [0/20], Loss 0.0\n",
      "Epoch [10/20], Batch [10/20], Loss 0.0\n",
      "Epoch [11/20], Batch [0/20], Loss 0.0\n",
      "Epoch [11/20], Batch [10/20], Loss 0.0\n",
      "Epoch [12/20], Batch [0/20], Loss 0.0\n",
      "Epoch [12/20], Batch [10/20], Loss 0.0\n",
      "Epoch [13/20], Batch [0/20], Loss 0.0\n",
      "Epoch [13/20], Batch [10/20], Loss 0.0\n",
      "Epoch [14/20], Batch [0/20], Loss 0.0\n",
      "Epoch [14/20], Batch [10/20], Loss 0.0\n",
      "Epoch [15/20], Batch [0/20], Loss 0.0\n",
      "Epoch [15/20], Batch [10/20], Loss 0.0\n",
      "Epoch [16/20], Batch [0/20], Loss 0.0\n",
      "Epoch [16/20], Batch [10/20], Loss 0.0\n",
      "Epoch [17/20], Batch [0/20], Loss 0.0\n",
      "Epoch [17/20], Batch [10/20], Loss 0.0\n",
      "Epoch [18/20], Batch [0/20], Loss 0.0\n",
      "Epoch [18/20], Batch [10/20], Loss 0.0\n",
      "Epoch [19/20], Batch [0/20], Loss 0.0\n",
      "Epoch [19/20], Batch [10/20], Loss 0.0\n",
      "Epoch [20/20], Batch [0/20], Loss 0.0\n",
      "Epoch [20/20], Batch [10/20], Loss 0.0\n",
      "Train teacher done.\n"
     ]
    }
   ],
   "source": [
    "ffd.train_teacher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2f4a988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train student start\n",
      "Epoch [1/20], Batch [0/20], Loss 0.0431215763092041\n",
      "Epoch [1/20], Batch [10/20], Loss 0.03219097852706909\n",
      "Epoch [2/20], Batch [0/20], Loss 0.03266716003417969\n",
      "Epoch [2/20], Batch [10/20], Loss 0.022750377655029297\n",
      "Epoch [3/20], Batch [0/20], Loss 0.02060335874557495\n",
      "Epoch [3/20], Batch [10/20], Loss 0.02368074655532837\n",
      "Epoch [4/20], Batch [0/20], Loss 0.021546363830566406\n",
      "Epoch [4/20], Batch [10/20], Loss 0.02171158790588379\n",
      "Epoch [5/20], Batch [0/20], Loss 0.019782721996307373\n",
      "Epoch [5/20], Batch [10/20], Loss 0.019554615020751953\n",
      "Epoch [6/20], Batch [0/20], Loss 0.01796180009841919\n",
      "Epoch [6/20], Batch [10/20], Loss 0.01750248670578003\n",
      "Epoch [7/20], Batch [0/20], Loss 0.017918944358825684\n",
      "Epoch [7/20], Batch [10/20], Loss 0.018960893154144287\n",
      "Epoch [8/20], Batch [0/20], Loss 0.01612168550491333\n",
      "Epoch [8/20], Batch [10/20], Loss 0.015807807445526123\n",
      "Epoch [9/20], Batch [0/20], Loss 0.016983866691589355\n",
      "Epoch [9/20], Batch [10/20], Loss 0.016386210918426514\n",
      "Epoch [10/20], Batch [0/20], Loss 0.015033066272735596\n",
      "Epoch [10/20], Batch [10/20], Loss 0.017446279525756836\n",
      "Epoch [11/20], Batch [0/20], Loss 0.01598447561264038\n",
      "Epoch [11/20], Batch [10/20], Loss 0.01586771011352539\n",
      "Epoch [12/20], Batch [0/20], Loss 0.016005516052246094\n",
      "Epoch [12/20], Batch [10/20], Loss 0.017489969730377197\n",
      "Epoch [13/20], Batch [0/20], Loss 0.01474684476852417\n",
      "Epoch [13/20], Batch [10/20], Loss 0.015609264373779297\n",
      "Epoch [14/20], Batch [0/20], Loss 0.016837477684020996\n",
      "Epoch [14/20], Batch [10/20], Loss 0.01584768295288086\n",
      "Epoch [15/20], Batch [0/20], Loss 0.01487189531326294\n",
      "Epoch [15/20], Batch [10/20], Loss 0.01506727933883667\n",
      "Epoch [16/20], Batch [0/20], Loss 0.0144081711769104\n",
      "Epoch [16/20], Batch [10/20], Loss 0.015557944774627686\n",
      "Epoch [17/20], Batch [0/20], Loss 0.0144692063331604\n",
      "Epoch [17/20], Batch [10/20], Loss 0.015402078628540039\n",
      "Epoch [18/20], Batch [0/20], Loss 0.014286160469055176\n",
      "Epoch [18/20], Batch [10/20], Loss 0.017565131187438965\n",
      "Epoch [19/20], Batch [0/20], Loss 0.013930678367614746\n",
      "Epoch [19/20], Batch [10/20], Loss 0.014452040195465088\n",
      "Epoch [20/20], Batch [0/20], Loss 0.015120387077331543\n",
      "Epoch [20/20], Batch [10/20], Loss 0.016129612922668457\n",
      "Train student end.\n"
     ]
    }
   ],
   "source": [
    "ffd.train_student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff25f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "pred = ffd.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "312c6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = ffd.test_dataset.X.reshape(100, -1).cpu().detach().numpy()\n",
    "test_y = ffd.test_dataset.y.cpu().detach().numpy()\n",
    "test_z = ffd.test_dataset.z.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d8ebaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "      <th>Male</th>\n",
       "      <th>Heavy_Makeup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5      6     7     8      9  ...  12280  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0    0.0  ...    6.0   \n",
       "1  97.0  63.0  35.0  98.0  64.0  36.0  101.0  66.0  37.0  106.0  ...  206.0   \n",
       "2  32.0  24.0  13.0  31.0  23.0  12.0   31.0  23.0  12.0   30.0  ...   11.0   \n",
       "3   1.0   1.0   0.0   1.0   1.0   0.0    1.0   1.0   0.0    1.0  ...   64.0   \n",
       "4  77.0  51.0  60.0  72.0  51.0  56.0   65.0  52.0  52.0   62.0  ...  144.0   \n",
       "\n",
       "   12281  12282  12283  12284  12285  12286  12287  Male  Heavy_Makeup  \n",
       "0    3.0   27.0    2.0    1.0    5.0    0.0    0.0     0             0  \n",
       "1  213.0  221.0  207.0  213.0  221.0  208.0  212.0     0             0  \n",
       "2   24.0   86.0  100.0  119.0  124.0  144.0  165.0     0             0  \n",
       "3   44.0   65.0   64.0   44.0   65.0   64.0   43.0     0             0  \n",
       "4  103.0  213.0  179.0  136.0  204.0  177.0  132.0     0             0  \n",
       "\n",
       "[5 rows x 12290 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measuring bias\n",
    "df = pd.DataFrame(test_X)\n",
    "df['Male'] = test_y\n",
    "df['Heavy_Makeup'] = test_z\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5e02124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[1.0] listed but not observed for feature Heavy_Makeup\n"
     ]
    }
   ],
   "source": [
    "aif_data = aifData(df=df, label_name='Male', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Heavy_Makeup'], privileged_classes=[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31749e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.0, 'TNR': 1.0, 'FPR': 0.0, 'FNR': 0.0, 'PPV': 0.0, 'NPV': 1.0, 'FDR': 0.0, 'FOR': 0.0, 'ACC': 1.0}\n",
      "Error rate:  0.0\n",
      "Average odds difference:  0.0\n",
      "Average absolute odds difference:  0.0\n",
      "Selection rate:  0.0\n",
      "Disparate impact:  0\n",
      "Statistical parity difference:  0.0\n",
      "Generalized entropy index:  0.0\n",
      "Theil index:  0.0\n",
      "Equal opportunity difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "clsMetric = ClassificationMetric(aif_data, privilege=[{'Heavy_Makeup': 1}], unprivilege=[{'Heavy_Makeup': 0}],\n",
    "                                prediction_vector=pred, target_label_name='Male')\n",
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55534fde",
   "metadata": {},
   "source": [
    "#### 3.2.3. Fairness VAE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ea22157",
   "metadata": {},
   "source": [
    "Reference (https://github.com/sungho-CoolG/Fairness-VAE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "341d1ce6",
   "metadata": {},
   "source": [
    "Fairness VAE can be used only on image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdbccbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on [[[  cpu  ]]] device.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.sota.FairnessVAE import fVAEDataset, FairnessVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0c0f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RawDataSet('./CelebA_samples.csv', header=0, seperator=',', \n",
    "                 target_col_name='Male', bias_col_name='Heavy_Makeup', cate_cols=['Male', 'Heavy_Makeup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393adcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvae = FairnessVAE(dataset = rds,\n",
    "                  z_dim = 10,\n",
    "                  batch_size = 20,\n",
    "                  num_epochs = 10,\n",
    "                  image_shape = (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68d9bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training upstream start\n",
      "Epoch [001]   VAE loss: 8216.741   Discriminator loss: 2.444\n",
      "Epoch [002]   VAE loss: 8172.522   Discriminator loss: 79.178\n",
      "Epoch [003]   VAE loss: 8106.138   Discriminator loss: 1383.587\n",
      "Epoch [004]   VAE loss: 7858.494   Discriminator loss: 12996.923\n",
      "Epoch [005]   VAE loss: 5632.970   Discriminator loss: 175547.078\n",
      "Epoch [006]   VAE loss: 1311.787   Discriminator loss: 1959365.375\n",
      "Epoch [007]   VAE loss: 344.635   Discriminator loss: 4482038.500\n",
      "Epoch [008]   VAE loss: -287.111   Discriminator loss: 15891211.000\n",
      "Epoch [009]   VAE loss: -2691.147   Discriminator loss: 89651440.000\n",
      "Epoch [010]   VAE loss: -12560.896   Discriminator loss: 407197440.000\n",
      "### Upstream training done.\n"
     ]
    }
   ],
   "source": [
    "fvae.train_upstream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f1aed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Downstream training start.\n",
      "Epoch [001]   VAE loss: -8005843.000   Discriminator loss: 0.000\n",
      "Epoch [002]   VAE loss: -7971678.500   Discriminator loss: 0.000\n",
      "Epoch [003]   VAE loss: -7812424.000   Discriminator loss: 0.000\n",
      "Epoch [004]   VAE loss: -8093974.500   Discriminator loss: 0.000\n",
      "Epoch [005]   VAE loss: -8115528.000   Discriminator loss: 0.000\n",
      "Epoch [006]   VAE loss: -7988520.000   Discriminator loss: 0.000\n",
      "Epoch [007]   VAE loss: -8178860.000   Discriminator loss: 0.000\n",
      "Epoch [008]   VAE loss: -8053573.000   Discriminator loss: 0.000\n",
      "Epoch [009]   VAE loss: -8034507.000   Discriminator loss: 0.000\n",
      "Epoch [010]   VAE loss: -7963781.500   Discriminator loss: 0.000\n",
      "### Downstream training done.\n"
     ]
    }
   ],
   "source": [
    "fvae.train_downstream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fc2d05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Evaluation start.\n",
      "### Evaluation done.\n"
     ]
    }
   ],
   "source": [
    "pred = fvae.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbd94819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[1.0] listed but not observed for feature Heavy_Makeup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.0, 'TNR': 1.0, 'FPR': 0.0, 'FNR': 0.0, 'PPV': 0.0, 'NPV': 1.0, 'FDR': 0.0, 'FOR': 0.0, 'ACC': 1.0}\n",
      "Error rate:  0.0\n",
      "Average odds difference:  0.0\n",
      "Average absolute odds difference:  0.0\n",
      "Selection rate:  0.0\n",
      "Disparate impact:  0\n",
      "Statistical parity difference:  0.0\n",
      "Generalized entropy index:  0.0\n",
      "Theil index:  0.0\n",
      "Equal opportunity difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "feature_set = fvae.test_dataset.feature.cpu().detach().numpy()\n",
    "target_set = fvae.test_dataset.target.cpu().detach().numpy()\n",
    "bias_set = fvae.test_dataset.bias.cpu().detach().numpy()\n",
    "\n",
    "df = pd.DataFrame(feature_set)\n",
    "df['Male'] = target_set\n",
    "df['Heavy_Makeup'] = bias_set\n",
    "\n",
    "aif_data = aifData(df=df, label_name='Male', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Heavy_Makeup'], privileged_classes=[[1]])\n",
    "\n",
    "clsMetric = ClassificationMetric(aif_data, privilege=[{'Heavy_Makeup': 1}], unprivilege=[{'Heavy_Makeup': 0}],\n",
    "                                prediction_vector=pred, target_label_name='Male')\n",
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3a8cf",
   "metadata": {},
   "source": [
    "#### 3.2.4. Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4461359c",
   "metadata": {},
   "source": [
    "Reference (https://github.com/Gyeongjo/FairClassifier_using_KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c23896dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "rds = RawDataSet('sample.npy', target_col_idx=3, bias_col_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac529a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on [[[  cpu  ]]] device.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.sota.KernelDensityEstimator import KDEmodel\n",
    "\n",
    "kde = KDEmodel(rawdata=rds, fairness_notion='DP', batch_size=32, n_epoch=20, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8bf5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model start.\n",
      "Train model done.tch [12/12], Cost: 0.5919\n"
     ]
    }
   ],
   "source": [
    "kde.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1bc92f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start.\n",
      "Evaluation done.\n"
     ]
    }
   ],
   "source": [
    "pred = kde.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2898f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = kde.test_data.X.cpu().detach().numpy()\n",
    "target = kde.test_data.y.cpu().detach().numpy()\n",
    "bias = kde.test_data.z.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57357824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Target</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.758807</td>\n",
       "      <td>0.600065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.554044</td>\n",
       "      <td>0.843816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350958</td>\n",
       "      <td>0.762025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503366</td>\n",
       "      <td>0.612485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461010</td>\n",
       "      <td>0.550399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2  Target  Bias\n",
       "0  0.758807  0.600065  1.0       1     1\n",
       "1  0.554044  0.843816  1.0       0     1\n",
       "2  0.350958  0.762025  0.0       1     0\n",
       "3  0.503366  0.612485  0.0       0     0\n",
       "4  0.461010  0.550399  1.0       1     1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(feature)\n",
    "df['Target'] = target\n",
    "df['Bias'] = bias\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "911e5358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.5714285714285714, 'TNR': 0.43137254901960786, 'FPR': 0.5686274509803921, 'FNR': 0.42857142857142855, 'PPV': 0.49122807017543857, 'NPV': 0.5116279069767442, 'FDR': 0.5087719298245614, 'FOR': 0.4883720930232558, 'ACC': 0.5}\n",
      "Error rate:  0.5\n",
      "Average odds difference:  0.2914910600255427\n",
      "Average absolute odds difference:  0.2914910600255427\n",
      "Selection rate:  0.57\n",
      "Disparate impact:  1.6669750231267346\n",
      "Statistical parity difference:  0.28944199116820557\n",
      "Generalized entropy index:  0.21159122085047996\n",
      "Theil index:  0.2952846669423606\n",
      "Equal opportunity difference:  0.21724137931034476\n"
     ]
    }
   ],
   "source": [
    "aif_data = aifData(df=df, label_name='Target', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Bias'], privileged_classes=[[1]])\n",
    "clsMetric = ClassificationMetric(aif_data, privilege=[{'Bias': 1}], unprivilege=[{'Bias': 0}],\n",
    "                                prediction_vector=pred, target_label_name='Target')\n",
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddd9cc",
   "metadata": {},
   "source": [
    "#### 3.2.5. Learning from Fairness"
   ]
  },
  {
   "cell_type": "raw",
   "id": "149baeef",
   "metadata": {},
   "source": [
    "Reference (https://github.com/alinlab/LfF)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b00ddd7a",
   "metadata": {},
   "source": [
    "Fairness VAE can be used only on image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ce2e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSet import RawDataSet\n",
    "\n",
    "# Data\n",
    "rds = RawDataSet('CelebA_samples.csv', target_col_name='Male', bias_col_name='Heavy_Makeup')\n",
    "rds.target = (rds.target > 0)*1\n",
    "rds.bias = (rds.bias > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ffd7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on [[[  cpu  ]]] device.\n"
     ]
    }
   ],
   "source": [
    "from Algorithms.sota.LearningFromFairness import LfFmodel\n",
    "\n",
    "lfm = LfFmodel(rawdata=rds, n_epoch=20, batch_size=16, learning_rate=0.01, image_shape=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc9d2e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start\n",
      "Epoch 0/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 1/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 2/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 3/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 4/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 5/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 6/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 7/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 8/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 9/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 10/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 11/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 12/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 13/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 14/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 15/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 16/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 17/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 18/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Epoch 19/20 :  Loss nan | valid_accuracy_b nan | valid_accuracy_d nan\n",
      "Training end\n"
     ]
    }
   ],
   "source": [
    "lfm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "589fae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, bias_list, label_list, predict_list = lfm.evaluate(lfm.model_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ae89f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = lfm.test_dataset.X.cpu().detach().numpy()\n",
    "bias = lfm.test_dataset.z.cpu().detach().numpy()\n",
    "target = lfm.test_dataset.y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be690a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "      <th>Target</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0    1.0    2.0    4.0    1.0    2.0    4.0    1.0    2.0    4.0    1.0  ...   \n",
       "1    2.0    2.0    4.0    2.0    2.0    4.0    2.0    2.0    4.0    2.0  ...   \n",
       "2  117.0  117.0  119.0  120.0  120.0  122.0  124.0  124.0  126.0  128.0  ...   \n",
       "3  192.0  195.0  214.0  192.0  195.0  214.0  192.0  195.0  214.0  192.0  ...   \n",
       "4  254.0  253.0  190.0  255.0  253.0  193.0  255.0  254.0  196.0  254.0  ...   \n",
       "\n",
       "   12280  12281  12282  12283  12284  12285  12286  12287  Target  Bias  \n",
       "0   23.0   18.0   30.0   31.0   26.0   26.0   31.0   26.0       0     1  \n",
       "1  101.0   73.0  125.0  101.0   76.0  152.0  130.0  106.0       0     0  \n",
       "2  123.0   89.0  180.0  120.0   86.0  174.0  114.0   79.0       0     1  \n",
       "3  133.0  160.0  138.0  136.0  146.0  149.0  138.0  142.0       0     1  \n",
       "4  160.0  239.0  125.0  173.0  193.0  169.0  182.0  167.0       1     0  \n",
       "\n",
       "[5 rows x 12290 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(feature)\n",
    "df['Target'] = target\n",
    "df['Bias'] = bias\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "675e29e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measure:  {'TPR': 0.6136363636363636, 'TNR': 0.4642857142857143, 'FPR': 0.5357142857142857, 'FNR': 0.38636363636363635, 'PPV': 0.47368421052631576, 'NPV': 0.6046511627906976, 'FDR': 0.5263157894736842, 'FOR': 0.3953488372093023, 'ACC': 0.53}\n",
      "Error rate:  0.47\n",
      "Average odds difference:  0.2805023923444976\n",
      "Average absolute odds difference:  0.33313397129186606\n",
      "Selection rate:  0.57\n",
      "Disparate impact:  1.0506912442396312\n",
      "Statistical parity difference:  0.028013582342954146\n",
      "Generalized entropy index:  0.17742188111833354\n",
      "Theil index:  0.24582511801554485\n",
      "Equal opportunity difference:  0.6136363636363636\n"
     ]
    }
   ],
   "source": [
    "aif_data = aifData(df=df, label_name='Target', favorable_classes=[1],\n",
    "                  protected_attribute_names=['Bias'], privileged_classes=[[1]])\n",
    "clsMetric = ClassificationMetric(aif_data, privilege=[{'Bias': 1}], unprivilege=[{'Bias': 0}],\n",
    "                                prediction_vector=pred, target_label_name='Target')\n",
    "print('Performance measure: ', clsMetric.performance)\n",
    "print('Error rate: ', clsMetric.error_rate())\n",
    "print('Average odds difference: ', clsMetric.average_odds_difference())\n",
    "print('Average absolute odds difference: ', clsMetric.average_abs_odds_difference())\n",
    "print('Selection rate: ', clsMetric.selection_rate())\n",
    "print('Disparate impact: ', clsMetric.disparate_impact())\n",
    "print('Statistical parity difference: ', clsMetric.statistical_parity_difference())\n",
    "print('Generalized entropy index: ', clsMetric.generalized_entropy_index())\n",
    "print('Theil index: ', clsMetric.theil_index())\n",
    "print('Equal opportunity difference: ', clsMetric.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1dc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
